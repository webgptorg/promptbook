# Version `0.92.0` _(2025-05-13)_

Models and Migrations and processing big tables

-   Models are picked by description
-   During preparation of the pipeline, not single model picked but all models which are relevant for task are sorted by relevance
-   Make real RAG of knowledge
-   Remove "(boilerplate)" from model names
-   Sort model providers by relevance
-   Export utility function `filterModels` from `@promptbook/core`
-   All OpenAI models contain description
-   All Anthropic models contain description
-   All DeepSeek models contain description
-   All Google models contain description
-   Fix remote server `POST` `/login`
-   Update and fix all status codes and responses in `openapi`
-   Migrate `JSON.parse` -> `jsonParse` _(preparation for formats)_
-   Migrate `papaparse.parse` -> `csvParse` _(preparation for formats)_
-   Rename `FormatDefinition` -> `FormatParser`
-   Limit rate of requests to models
-   Autoheal `\r` in `CsvFormatParser` ~~`CsvFormatDefinition`~~
-   Add `getIndexedDbStorage`
-   Pipeline migrations
-   Add formfactor `COMPLETION` which emulates `Completion` variant of the model
-   Add JSDoc annotations to all entities which are exported from any package
-   When processing more than 50 values, if many items pass but some fail, use "~" for failed value and just console log the error.
-   Fix OpenAI pricing
-   Fix LLM cache
-   Add `title` and `promptbookVersion` to `ExecutionTask`
-   Cache `getLocalStorage`, `getSessionStorage` and `getIndexedDbStorage`
-   Pass `databaseName` and `storeName` into `getIndexedDbStorage`
-   Fix `AzureOpenAiExecutionTools`
-   Add `maxRequestsPerMinute` to LLM provider boilerplate configurations
-   âœ¨Auto-enhance model providers, _try autonomous agent to work on Promptbook_
-   âœ¨Auto-fix grammar and typos

> `0.90.0` and `0.91.0` were skipped
