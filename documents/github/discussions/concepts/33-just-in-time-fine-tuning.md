            <!--âš ï¸ WARNING: This code has been generated so that any manual changes will be overwritten-->

            # â³ Just-in-time fine-tuning

            - Author: [hejny](https://github.com/hejny)
            - Created at: 6/23/2024, 10:59:36 PM
            - Updated at: 6/24/2024, 2:58:55 PM
            - Category: Concepts
            - Discussion: #33

            When you use language models, you have a choice:

            1) use a strong model (such as gpt-4) and pay nothing up front, but more as you go.
            2) You can fine tune the model, which requires a lot of data and you also have to pay for training, but then you can get better results and pay less.

            > â„¹ There is an analogy between this and compilation vs. interpretation.
            > ðŸ’¡ But there is a third option, just-in-time compilation.


            We can do something similar with model training and fine tuning:


            3) Just use the strong model for the first x runs and then start fine tuning with the data from those x runs.

            ---

            See also https://github.com/webgptorg/promptbook/discussions/37

            ## Comments

### Comment by hejny on 6/24/2024, 2:49:10 PM

## What we tried

_(Describe our experience here)_

---

### Comment by hejny on 6/24/2024, 2:58:55 PM

## ðŸ”Ž Existing solutions

_(Do some research / discussion)_

-   Has anyone else had the same problem?
-   Has a project come up with the solution
-   Is there a research paper about it?
-   Is there an article, video, podcast about it?
-   Is this even a good idea?
