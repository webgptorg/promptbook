[x]

[âœ¨ðŸ–‹] Agents should learn from the conversations

-   Agent is defined here `/src/llm-providers/agent/Agent.ts`
-   You are working with the `Agents Server` application `/apps/agents-server`
-   Keep in mind the DRY _(don't repeat yourself)_ principle.

---

[x] _<- TODO: Problemeatic, not working_
[ ]

[âœ¨ðŸ–‹] When learning from conversations, show the updated agent source right away in the book

-   In `/agents/[agentName]/book+chat` you can chat with the agent but source in the editor is not updated right away but after page reload
-   Make sure that when agent learns from the conversations, the updated source is reflected right away in the book editor
-   You are working with the `Agents Server` application `/apps/agents-server`
-   Keep in mind the DRY _(don't repeat yourself)_ principle.

---

[x]

[âœ¨ðŸ–‹] Lernerned conversations should be used 1:1

-
-   You are working with the `Agents Server` application `/apps/agents-server`
-   Keep in mind the DRY _(don't repeat yourself)_ principle.

---

[ ]

[âœ¨ðŸ–‹] Do not add pair of learned `USER MESSAGE` and `AGENT MESSAGE` when the response came from there

-   Before each LLM call, we check if the last user message exists in the learned conversations, and if so, we provide the corresponding agent response right away
-   After that, we again add the pair of `USER MESSAGE` and `AGENT MESSAGE` to the learned conversations, which creates duplicate entries
-   Fix this by not adding the pair again when the response came from learned conversations
-   Add it only when the response was generated by the LLM
-   You are working with [Agent](/src/llm-providers/agent/Agent.ts)
-   You are working with the `Agents Server` application `/apps/agents-server`
-   Keep in mind the DRY _(don't repeat yourself)_ principle.
