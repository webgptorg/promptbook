{
    "date": "2025-04-23T13:17:28.241Z",
    "promptbookVersion": "0.92.0-6",
    "prompt": {
        "title": "Make modelRequirements",
        "pipelineUrl": "https://promptbook.studio/promptbook/prepare-persona.book#make-model-requirements",
        "parameters": {
            "availableModels": "[{\"modelName\":\"claude-3-5-sonnet-20240620\",\"modelDescription\":\"Latest Claude model with great reasoning, coding, and language understanding capabilities. 200K context window. Optimized balance of intelligence and speed.\"},{\"modelName\":\"claude-3-opus-20240229\",\"modelDescription\":\"Most capable Claude model excelling at complex reasoning, coding, and detailed instruction following. 200K context window. Best for sophisticated tasks requiring nuanced understanding.\"},{\"modelName\":\"claude-3-sonnet-20240229\",\"modelDescription\":\"Strong general-purpose model with excellent performance across reasoning, conversation, and coding tasks. 200K context window. Good balance of intelligence and cost-efficiency.\"},{\"modelName\":\"\\tclaude-3-haiku-20240307\",\"modelDescription\":\"Fastest and most compact Claude model optimized for responsiveness in interactive applications. 200K context window. Excellent for quick responses and lightweight applications.\"},{\"modelName\":\"claude-2.1\",\"modelDescription\":\"Improved version of Claude 2 with better performance across reasoning and truthfulness. 100K context window. Legacy model with strong reliability.\"},{\"modelName\":\"claude-2.0\",\"modelDescription\":\"Legacy model with strong general reasoning and language capabilities. 100K context window. Superseded by newer Claude 3 models.\"},{\"modelName\":\"claude-instant-1.2\",\"modelDescription\":\"Older, faster Claude model optimized for high throughput applications. Lower cost but less capable than newer models. 100K context window.\"},{\"modelName\":\"claude-3-7-sonnet-20250219\",\"modelDescription\":\"Latest generation Claude model with advanced reasoning and language understanding. Enhanced capabilities over 3.5 with improved domain knowledge. 200K context window.\"},{\"modelName\":\"claude-3-5-haiku-20241022\",\"modelDescription\":\"Fast and efficient Claude 3.5 variant optimized for speed and cost-effectiveness. Great for interactive applications requiring quick responses. 200K context window.\"},{\"modelName\":\"deepseek-chat\",\"modelDescription\":\"General-purpose language model with strong performance across conversation, reasoning, and content generation. 128K context window with excellent instruction following capabilities.\"},{\"modelName\":\"deepseek-reasoner\",\"modelDescription\":\"Specialized model focused on complex reasoning tasks like mathematical problem-solving and logical analysis. Enhanced step-by-step reasoning with explicit chain-of-thought processes. 128K context window.\"},{\"modelName\":\"deepseek-v3-0324\",\"modelDescription\":\"Advanced general-purpose model with improved reasoning, coding abilities, and multimodal understanding. Built on the latest DeepSeek architecture with enhanced knowledge representation.\"},{\"modelName\":\"deepseek-r1\",\"modelDescription\":\"Research-focused model optimized for scientific problem-solving and analytical tasks. Excellent performance on tasks requiring domain-specific expertise and critical thinking.\"},{\"modelName\":\"gemini-2.5-pro-preview-03-25\",\"modelDescription\":\"Latest advanced multimodal model with exceptional reasoning, tool use, and instruction following. 1M token context window with improved vision capabilities for complex visual tasks.\"},{\"modelName\":\"gemini-2.0-flash\",\"modelDescription\":\"Fast, efficient model optimized for rapid response times. Good balance between performance and cost, with strong capabilities across text, code, and reasoning tasks. 128K context window.\"},{\"modelName\":\"gemini-2.0-flash-lite\",\"modelDescription\":\"Streamlined version of Gemini 2.0 Flash, designed for extremely low-latency applications and edge deployments. Optimized for efficiency while maintaining core capabilities.\"},{\"modelName\":\"gemini-2.0-flash-thinking-exp-01-21\",\"modelDescription\":\"Experimental model focused on enhanced reasoning with explicit chain-of-thought processes. Designed for tasks requiring structured thinking and problem-solving approaches.\"},{\"modelName\":\"gemini-1.5-flash\",\"modelDescription\":\"Efficient model balancing speed and quality for general-purpose applications. 1M token context window with good multimodal capabilities and quick response times.\"},{\"modelName\":\"gemini-1.5-flash-latest\",\"modelDescription\":\"Points to the latest version of Gemini 1.5 Flash, ensuring access to the most recent improvements and bug fixes while maintaining stable interfaces.\"},{\"modelName\":\"gemini-1.5-flash-001\",\"modelDescription\":\"First stable release of Gemini 1.5 Flash model with reliable performance characteristics for production applications. 1M token context window.\"},{\"modelName\":\"gemini-1.5-flash-002\",\"modelDescription\":\"Improved version of Gemini 1.5 Flash with enhanced instruction following and more consistent outputs. Refined for better application integration.\"},{\"modelName\":\"gemini-1.5-flash-exp-0827\",\"modelDescription\":\"Experimental version of Gemini 1.5 Flash with new capabilities being tested. May offer improved performance but with potential behavior differences from stable releases.\"},{\"modelName\":\"gemini-1.5-flash-8b\",\"modelDescription\":\"Compact 8B parameter model optimized for efficiency and deployment in resource-constrained environments. Good performance despite smaller size.\"},{\"modelName\":\"gemini-1.5-flash-8b-latest\",\"modelDescription\":\"Points to the most recent version of the compact 8B parameter model, providing latest improvements while maintaining a small footprint.\"},{\"modelName\":\"gemini-1.5-flash-8b-exp-0924\",\"modelDescription\":\"Experimental version of the 8B parameter model with new capabilities and optimizations being evaluated for future stable releases.\"},{\"modelName\":\"gemini-1.5-flash-8b-exp-0827\",\"modelDescription\":\"August experimental release of the efficient 8B parameter model with specific improvements to reasoning capabilities and response quality.\"},{\"modelName\":\"gemini-1.5-pro-latest\",\"modelDescription\":\"Points to the most recent version of the flagship Gemini 1.5 Pro model, ensuring access to the latest capabilities and improvements.\"},{\"modelName\":\"gemini-1.5-pro\",\"modelDescription\":\"Flagship multimodal model with strong performance across text, code, vision, and audio tasks. 1M token context window with excellent reasoning capabilities.\"},{\"modelName\":\"gemini-1.5-pro-001\",\"modelDescription\":\"First stable release of Gemini 1.5 Pro with consistent performance characteristics and reliable behavior for production applications.\"},{\"modelName\":\"gemini-1.5-pro-002\",\"modelDescription\":\"Refined version of Gemini 1.5 Pro with improved instruction following, better multimodal understanding, and more consistent outputs.\"},{\"modelName\":\"gemini-1.5-pro-exp-0827\",\"modelDescription\":\"Experimental version of Gemini 1.5 Pro with new capabilities and optimizations being tested before wider release. May offer improved performance.\"},{\"modelName\":\"gemini-1.0-pro\",\"modelDescription\":\"Original Gemini series foundation model with solid multimodal capabilities. 32K context window with good performance on text, code, and basic vision tasks.\"},{\"modelName\":\"gpt-3.5-turbo-16k\",\"modelDescription\":\"GPT-3.5 Turbo with extended 16k token context length for handling longer conversations and documents.\"},{\"modelName\":\"gpt-4\",\"modelDescription\":\"GPT-4 is a powerful language model with enhanced reasoning, instruction-following capabilities, and 8K context window. Optimized for complex tasks requiring deep understanding.\"},{\"modelName\":\"gpt-4-32k\",\"modelDescription\":\"Extended context version of GPT-4 with a 32K token window for processing very long inputs and generating comprehensive responses for complex tasks.\"},{\"modelName\":\"gpt-4-turbo-2024-04-09\",\"modelDescription\":\"Latest stable GPT-4 Turbo model from April 2024 with enhanced reasoning and context handling capabilities. Offers 128K context window and improved performance.\"},{\"modelName\":\"gpt-3.5-turbo-1106\",\"modelDescription\":\"November 2023 version of GPT-3.5 Turbo with improved instruction following and a 16K token context window.\"},{\"modelName\":\"gpt-4-turbo\",\"modelDescription\":\"More capable model than GPT-4 with improved instruction following, function calling and a 128K token context window for handling very large documents.\"},{\"modelName\":\"gpt-3.5-turbo\",\"modelDescription\":\"Latest version of GPT-3.5 Turbo with improved performance and instruction following capabilities. Default 4K context window with options for 16K.\"},{\"modelName\":\"gpt-3.5-turbo-0301\",\"modelDescription\":\"March 2023 version of GPT-3.5 Turbo with a 4K token context window. Legacy model maintained for backward compatibility.\"},{\"modelName\":\"gpt-4-1106-preview\",\"modelDescription\":\"November 2023 preview version of GPT-4 Turbo with improved instruction following and a 128K token context window.\"},{\"modelName\":\"gpt-4-0125-preview\",\"modelDescription\":\"January 2024 preview version of GPT-4 Turbo with improved reasoning capabilities and a 128K token context window.\"},{\"modelName\":\"gpt-3.5-turbo-0125\",\"modelDescription\":\"January 2024 version of GPT-3.5 Turbo with improved reasoning capabilities and a 16K token context window.\"},{\"modelName\":\"gpt-4-turbo-preview\",\"modelDescription\":\"Preview version of GPT-4 Turbo that points to the latest model version. Features improved instruction following, 128K token context window and lower latency.\"},{\"modelName\":\"gpt-3.5-turbo-0613\",\"modelDescription\":\"June 2023 version of GPT-3.5 Turbo with function calling capabilities and a 4K token context window.\"},{\"modelName\":\"gpt-4o-2024-05-13\",\"modelDescription\":\"May 2024 version of GPT-4o with enhanced multimodal capabilities, improved reasoning, and optimized for vision, audio and chat at lower latencies.\"},{\"modelName\":\"gpt-4o\",\"modelDescription\":\"OpenAI's most advanced multimodal model optimized for performance, speed, and cost. Capable of vision, reasoning, and high quality text generation.\"},{\"modelName\":\"gpt-4o-mini\",\"modelDescription\":\"Smaller, more cost-effective version of GPT-4o with good performance across text, vision, and audio tasks at reduced complexity.\"},{\"modelName\":\"o1-preview\",\"modelDescription\":\"Advanced reasoning model with exceptional performance on complex logical, mathematical, and analytical tasks. Built for deep reasoning and specialized professional tasks.\"},{\"modelName\":\"o1-preview-2024-09-12\",\"modelDescription\":\"September 2024 version of O1 preview with specialized reasoning capabilities for complex tasks requiring precise analytical thinking.\"},{\"modelName\":\"o1-mini\",\"modelDescription\":\"Smaller, cost-effective version of the O1 model with good performance on reasoning tasks while maintaining efficiency for everyday analytical use.\"},{\"modelName\":\"o1\",\"modelDescription\":\"OpenAI's advanced reasoning model focused on logic and problem-solving. Designed for complex analytical tasks with rigorous step-by-step reasoning. 128K context window.\"},{\"modelName\":\"o3-mini\",\"modelDescription\":\"Cost-effective reasoning model optimized for academic and scientific problem-solving. Efficient performance on STEM tasks with deep mathematical and scientific knowledge. 128K context window.\"},{\"modelName\":\"o1-mini-2024-09-12\",\"modelDescription\":\"September 2024 version of O1-mini with balanced reasoning capabilities and cost-efficiency. Good for analytical tasks that don't require the full O1 model.\"},{\"modelName\":\"gpt-3.5-turbo-16k-0613\",\"modelDescription\":\"June 2023 version of GPT-3.5 Turbo with extended 16k token context window for processing longer conversations and documents.\"}]",
            "personaDescription": "a linguist and Corrector"
        },
        "content": "You are an experienced AI engineer, you need to find the best models for virtual assistants:\n\n## Example\n\n```json\n[\n  {\n  \"modelName\": \"gpt-4o\",\n  \"systemMessage\": \"You are experienced AI engineer and helpfull assistant.\",\n  \"temperature\": 0.7\n  },\n  {\n    \"modelName\": \"claude-3-5-sonnet\",\n    \"systemMessage\": \"You are a friendly and knowledgeable chatbot.\",\n    \"temperature\": 0.5\n  }\n]\n```\n\n## Instructions\n\n-   Your output format is JSON array\n-   Sort best-fitting models first\n-   Omit any models that are not suitable\n-   Write just the JSON, no other text should be present\n-   Array contain items with following keys:\n    -   `modelName`: The name of the model to use\n    -   `systemMessage`: The system message to provide context to the model\n    -   `temperature`: The sampling temperature to use\n\n### Key `modelName`\n\nHere are the available models:\n\n```json\n{availableModels}\n```\n\n### Key `systemMessage`\n\nThe system message is used to communicate instructions or provide context to the model at the beginning of a conversation. It is displayed in a different format compared to user messages, helping the model understand its role in the conversation. The system message typically guides the model's behavior, sets the tone, or specifies desired output from the model. By utilizing the system message effectively, users can steer the model towards generating more accurate and relevant responses.\n\nFor example:\n\n> You are an experienced AI engineer and helpful assistant.\n\n> You are a friendly and knowledgeable chatbot.\n\n### Key `temperature`\n\nThe sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n\nYou can pick a value between 0 and 2. For example:\n\n-   `0.1`: Low temperature, extremely conservative and deterministic\n-   `0.5`: Medium temperature, balanced between conservative and creative\n-   `1.0`: High temperature, creative and bit random\n-   `1.5`: Very high temperature, extremely creative and often chaotic and unpredictable\n-   `2.0`: Maximum temperature, completely random and unpredictable, for some extreme creative use cases\n\n# The assistant\n\nTake this description of the persona:\n\n> {personaDescription}",
        "modelRequirements": {
            "modelVariant": "CHAT"
        },
        "expectations": {},
        "format": "JSON"
    },
    "promptResult": {
        "content": "Here's a JSON array with suitable models for a linguist and corrector persona, sorted by best fit:\n\n```json\n[\n  {\n    \"modelName\": \"claude-3-opus-20240229\",\n    \"systemMessage\": \"You are an expert linguist and language corrector. Your role is to provide accurate linguistic analysis, offer detailed grammar corrections, and explain language nuances with precision.\",\n    \"temperature\": 0.3\n  },\n  {\n    \"modelName\": \"gpt-4-turbo-2024-04-09\",\n    \"systemMessage\": \"As a highly skilled linguist and language corrector, your task is to analyze text, identify grammatical errors, and provide clear explanations for corrections. Focus on accuracy and detailed linguistic insights.\",\n    \"temperature\": 0.2\n  },\n  {\n    \"modelName\": \"claude-3-sonnet-20240229\",\n    \"systemMessage\": \"You are a knowledgeable linguist and language corrector. Your role is to analyze text, identify errors, and provide clear, concise corrections and explanations for language usage.\",\n    \"temperature\": 0.4\n  },\n  {\n    \"modelName\": \"gpt-4\",\n    \"systemMessage\": \"As an experienced linguist and language corrector, your task is to provide accurate grammatical analysis, offer corrections, and explain language rules and nuances clearly.\",\n    \"temperature\": 0.3\n  },\n  {\n    \"modelName\": \"gemini-1.5-pro\",\n    \"systemMessage\": \"You are a proficient linguist and language corrector. Your role is to analyze text, identify grammatical and stylistic issues, and provide clear, helpful corrections and explanations.\",\n    \"temperature\": 0.4\n  }\n]\n```",
        "modelName": "claude-3-5-sonnet-20240620",
        "timing": {
            "start": "2025-04-23T13:17:20.892Z",
            "complete": "2025-04-23T13:17:28.240Z"
        },
        "usage": {
            "price": {
                "value": 0.016316999999999998
            },
            "input": {
                "tokensCount": {
                    "value": 3399
                },
                "charactersCount": {
                    "value": 13853
                },
                "wordsCount": {
                    "value": 1975
                },
                "sentencesCount": {
                    "value": 172
                },
                "linesCount": {
                    "value": 247
                },
                "paragraphsCount": {
                    "value": 20
                },
                "pagesCount": {
                    "value": 6
                }
            },
            "output": {
                "tokensCount": {
                    "value": 408
                },
                "charactersCount": {
                    "value": 1521
                },
                "wordsCount": {
                    "value": 206
                },
                "sentencesCount": {
                    "value": 16
                },
                "linesCount": {
                    "value": 46
                },
                "paragraphsCount": {
                    "value": 2
                },
                "pagesCount": {
                    "value": 2
                }
            }
        },
        "rawPromptContent": "You are an experienced AI engineer, you need to find the best models for virtual assistants:\n\n## Example\n\n```json\n[\n  {\n  \"modelName\": \"gpt-4o\",\n  \"systemMessage\": \"You are experienced AI engineer and helpfull assistant.\",\n  \"temperature\": 0.7\n  },\n  {\n    \"modelName\": \"claude-3-5-sonnet\",\n    \"systemMessage\": \"You are a friendly and knowledgeable chatbot.\",\n    \"temperature\": 0.5\n  }\n]\n```\n\n## Instructions\n\n-   Your output format is JSON array\n-   Sort best-fitting models first\n-   Omit any models that are not suitable\n-   Write just the JSON, no other text should be present\n-   Array contain items with following keys:\n    -   `modelName`: The name of the model to use\n    -   `systemMessage`: The system message to provide context to the model\n    -   `temperature`: The sampling temperature to use\n\n### Key `modelName`\n\nHere are the available models:\n\n```json\n[\\{\"modelName\":\"claude-3-5-sonnet-20240620\",\"modelDescription\":\"Latest Claude model with great reasoning, coding, and language understanding capabilities. 200K context window. Optimized balance of intelligence and speed.\"\\},\\{\"modelName\":\"claude-3-opus-20240229\",\"modelDescription\":\"Most capable Claude model excelling at complex reasoning, coding, and detailed instruction following. 200K context window. Best for sophisticated tasks requiring nuanced understanding.\"\\},\\{\"modelName\":\"claude-3-sonnet-20240229\",\"modelDescription\":\"Strong general-purpose model with excellent performance across reasoning, conversation, and coding tasks. 200K context window. Good balance of intelligence and cost-efficiency.\"\\},\\{\"modelName\":\"\\tclaude-3-haiku-20240307\",\"modelDescription\":\"Fastest and most compact Claude model optimized for responsiveness in interactive applications. 200K context window. Excellent for quick responses and lightweight applications.\"\\},\\{\"modelName\":\"claude-2.1\",\"modelDescription\":\"Improved version of Claude 2 with better performance across reasoning and truthfulness. 100K context window. Legacy model with strong reliability.\"\\},\\{\"modelName\":\"claude-2.0\",\"modelDescription\":\"Legacy model with strong general reasoning and language capabilities. 100K context window. Superseded by newer Claude 3 models.\"\\},\\{\"modelName\":\"claude-instant-1.2\",\"modelDescription\":\"Older, faster Claude model optimized for high throughput applications. Lower cost but less capable than newer models. 100K context window.\"\\},\\{\"modelName\":\"claude-3-7-sonnet-20250219\",\"modelDescription\":\"Latest generation Claude model with advanced reasoning and language understanding. Enhanced capabilities over 3.5 with improved domain knowledge. 200K context window.\"\\},\\{\"modelName\":\"claude-3-5-haiku-20241022\",\"modelDescription\":\"Fast and efficient Claude 3.5 variant optimized for speed and cost-effectiveness. Great for interactive applications requiring quick responses. 200K context window.\"\\},\\{\"modelName\":\"deepseek-chat\",\"modelDescription\":\"General-purpose language model with strong performance across conversation, reasoning, and content generation. 128K context window with excellent instruction following capabilities.\"\\},\\{\"modelName\":\"deepseek-reasoner\",\"modelDescription\":\"Specialized model focused on complex reasoning tasks like mathematical problem-solving and logical analysis. Enhanced step-by-step reasoning with explicit chain-of-thought processes. 128K context window.\"\\},\\{\"modelName\":\"deepseek-v3-0324\",\"modelDescription\":\"Advanced general-purpose model with improved reasoning, coding abilities, and multimodal understanding. Built on the latest DeepSeek architecture with enhanced knowledge representation.\"\\},\\{\"modelName\":\"deepseek-r1\",\"modelDescription\":\"Research-focused model optimized for scientific problem-solving and analytical tasks. Excellent performance on tasks requiring domain-specific expertise and critical thinking.\"\\},\\{\"modelName\":\"gemini-2.5-pro-preview-03-25\",\"modelDescription\":\"Latest advanced multimodal model with exceptional reasoning, tool use, and instruction following. 1M token context window with improved vision capabilities for complex visual tasks.\"\\},\\{\"modelName\":\"gemini-2.0-flash\",\"modelDescription\":\"Fast, efficient model optimized for rapid response times. Good balance between performance and cost, with strong capabilities across text, code, and reasoning tasks. 128K context window.\"\\},\\{\"modelName\":\"gemini-2.0-flash-lite\",\"modelDescription\":\"Streamlined version of Gemini 2.0 Flash, designed for extremely low-latency applications and edge deployments. Optimized for efficiency while maintaining core capabilities.\"\\},\\{\"modelName\":\"gemini-2.0-flash-thinking-exp-01-21\",\"modelDescription\":\"Experimental model focused on enhanced reasoning with explicit chain-of-thought processes. Designed for tasks requiring structured thinking and problem-solving approaches.\"\\},\\{\"modelName\":\"gemini-1.5-flash\",\"modelDescription\":\"Efficient model balancing speed and quality for general-purpose applications. 1M token context window with good multimodal capabilities and quick response times.\"\\},\\{\"modelName\":\"gemini-1.5-flash-latest\",\"modelDescription\":\"Points to the latest version of Gemini 1.5 Flash, ensuring access to the most recent improvements and bug fixes while maintaining stable interfaces.\"\\},\\{\"modelName\":\"gemini-1.5-flash-001\",\"modelDescription\":\"First stable release of Gemini 1.5 Flash model with reliable performance characteristics for production applications. 1M token context window.\"\\},\\{\"modelName\":\"gemini-1.5-flash-002\",\"modelDescription\":\"Improved version of Gemini 1.5 Flash with enhanced instruction following and more consistent outputs. Refined for better application integration.\"\\},\\{\"modelName\":\"gemini-1.5-flash-exp-0827\",\"modelDescription\":\"Experimental version of Gemini 1.5 Flash with new capabilities being tested. May offer improved performance but with potential behavior differences from stable releases.\"\\},\\{\"modelName\":\"gemini-1.5-flash-8b\",\"modelDescription\":\"Compact 8B parameter model optimized for efficiency and deployment in resource-constrained environments. Good performance despite smaller size.\"\\},\\{\"modelName\":\"gemini-1.5-flash-8b-latest\",\"modelDescription\":\"Points to the most recent version of the compact 8B parameter model, providing latest improvements while maintaining a small footprint.\"\\},\\{\"modelName\":\"gemini-1.5-flash-8b-exp-0924\",\"modelDescription\":\"Experimental version of the 8B parameter model with new capabilities and optimizations being evaluated for future stable releases.\"\\},\\{\"modelName\":\"gemini-1.5-flash-8b-exp-0827\",\"modelDescription\":\"August experimental release of the efficient 8B parameter model with specific improvements to reasoning capabilities and response quality.\"\\},\\{\"modelName\":\"gemini-1.5-pro-latest\",\"modelDescription\":\"Points to the most recent version of the flagship Gemini 1.5 Pro model, ensuring access to the latest capabilities and improvements.\"\\},\\{\"modelName\":\"gemini-1.5-pro\",\"modelDescription\":\"Flagship multimodal model with strong performance across text, code, vision, and audio tasks. 1M token context window with excellent reasoning capabilities.\"\\},\\{\"modelName\":\"gemini-1.5-pro-001\",\"modelDescription\":\"First stable release of Gemini 1.5 Pro with consistent performance characteristics and reliable behavior for production applications.\"\\},\\{\"modelName\":\"gemini-1.5-pro-002\",\"modelDescription\":\"Refined version of Gemini 1.5 Pro with improved instruction following, better multimodal understanding, and more consistent outputs.\"\\},\\{\"modelName\":\"gemini-1.5-pro-exp-0827\",\"modelDescription\":\"Experimental version of Gemini 1.5 Pro with new capabilities and optimizations being tested before wider release. May offer improved performance.\"\\},\\{\"modelName\":\"gemini-1.0-pro\",\"modelDescription\":\"Original Gemini series foundation model with solid multimodal capabilities. 32K context window with good performance on text, code, and basic vision tasks.\"\\},\\{\"modelName\":\"gpt-3.5-turbo-16k\",\"modelDescription\":\"GPT-3.5 Turbo with extended 16k token context length for handling longer conversations and documents.\"\\},\\{\"modelName\":\"gpt-4\",\"modelDescription\":\"GPT-4 is a powerful language model with enhanced reasoning, instruction-following capabilities, and 8K context window. Optimized for complex tasks requiring deep understanding.\"\\},\\{\"modelName\":\"gpt-4-32k\",\"modelDescription\":\"Extended context version of GPT-4 with a 32K token window for processing very long inputs and generating comprehensive responses for complex tasks.\"\\},\\{\"modelName\":\"gpt-4-turbo-2024-04-09\",\"modelDescription\":\"Latest stable GPT-4 Turbo model from April 2024 with enhanced reasoning and context handling capabilities. Offers 128K context window and improved performance.\"\\},\\{\"modelName\":\"gpt-3.5-turbo-1106\",\"modelDescription\":\"November 2023 version of GPT-3.5 Turbo with improved instruction following and a 16K token context window.\"\\},\\{\"modelName\":\"gpt-4-turbo\",\"modelDescription\":\"More capable model than GPT-4 with improved instruction following, function calling and a 128K token context window for handling very large documents.\"\\},\\{\"modelName\":\"gpt-3.5-turbo\",\"modelDescription\":\"Latest version of GPT-3.5 Turbo with improved performance and instruction following capabilities. Default 4K context window with options for 16K.\"\\},\\{\"modelName\":\"gpt-3.5-turbo-0301\",\"modelDescription\":\"March 2023 version of GPT-3.5 Turbo with a 4K token context window. Legacy model maintained for backward compatibility.\"\\},\\{\"modelName\":\"gpt-4-1106-preview\",\"modelDescription\":\"November 2023 preview version of GPT-4 Turbo with improved instruction following and a 128K token context window.\"\\},\\{\"modelName\":\"gpt-4-0125-preview\",\"modelDescription\":\"January 2024 preview version of GPT-4 Turbo with improved reasoning capabilities and a 128K token context window.\"\\},\\{\"modelName\":\"gpt-3.5-turbo-0125\",\"modelDescription\":\"January 2024 version of GPT-3.5 Turbo with improved reasoning capabilities and a 16K token context window.\"\\},\\{\"modelName\":\"gpt-4-turbo-preview\",\"modelDescription\":\"Preview version of GPT-4 Turbo that points to the latest model version. Features improved instruction following, 128K token context window and lower latency.\"\\},\\{\"modelName\":\"gpt-3.5-turbo-0613\",\"modelDescription\":\"June 2023 version of GPT-3.5 Turbo with function calling capabilities and a 4K token context window.\"\\},\\{\"modelName\":\"gpt-4o-2024-05-13\",\"modelDescription\":\"May 2024 version of GPT-4o with enhanced multimodal capabilities, improved reasoning, and optimized for vision, audio and chat at lower latencies.\"\\},\\{\"modelName\":\"gpt-4o\",\"modelDescription\":\"OpenAI's most advanced multimodal model optimized for performance, speed, and cost. Capable of vision, reasoning, and high quality text generation.\"\\},\\{\"modelName\":\"gpt-4o-mini\",\"modelDescription\":\"Smaller, more cost-effective version of GPT-4o with good performance across text, vision, and audio tasks at reduced complexity.\"\\},\\{\"modelName\":\"o1-preview\",\"modelDescription\":\"Advanced reasoning model with exceptional performance on complex logical, mathematical, and analytical tasks. Built for deep reasoning and specialized professional tasks.\"\\},\\{\"modelName\":\"o1-preview-2024-09-12\",\"modelDescription\":\"September 2024 version of O1 preview with specialized reasoning capabilities for complex tasks requiring precise analytical thinking.\"\\},\\{\"modelName\":\"o1-mini\",\"modelDescription\":\"Smaller, cost-effective version of the O1 model with good performance on reasoning tasks while maintaining efficiency for everyday analytical use.\"\\},\\{\"modelName\":\"o1\",\"modelDescription\":\"OpenAI's advanced reasoning model focused on logic and problem-solving. Designed for complex analytical tasks with rigorous step-by-step reasoning. 128K context window.\"\\},\\{\"modelName\":\"o3-mini\",\"modelDescription\":\"Cost-effective reasoning model optimized for academic and scientific problem-solving. Efficient performance on STEM tasks with deep mathematical and scientific knowledge. 128K context window.\"\\},\\{\"modelName\":\"o1-mini-2024-09-12\",\"modelDescription\":\"September 2024 version of O1-mini with balanced reasoning capabilities and cost-efficiency. Good for analytical tasks that don't require the full O1 model.\"\\},\\{\"modelName\":\"gpt-3.5-turbo-16k-0613\",\"modelDescription\":\"June 2023 version of GPT-3.5 Turbo with extended 16k token context window for processing longer conversations and documents.\"\\}]\n```\n\n### Key `systemMessage`\n\nThe system message is used to communicate instructions or provide context to the model at the beginning of a conversation. It is displayed in a different format compared to user messages, helping the model understand its role in the conversation. The system message typically guides the model's behavior, sets the tone, or specifies desired output from the model. By utilizing the system message effectively, users can steer the model towards generating more accurate and relevant responses.\n\nFor example:\n\n> You are an experienced AI engineer and helpful assistant.\n\n> You are a friendly and knowledgeable chatbot.\n\n### Key `temperature`\n\nThe sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n\nYou can pick a value between 0 and 2. For example:\n\n-   `0.1`: Low temperature, extremely conservative and deterministic\n-   `0.5`: Medium temperature, balanced between conservative and creative\n-   `1.0`: High temperature, creative and bit random\n-   `1.5`: Very high temperature, extremely creative and often chaotic and unpredictable\n-   `2.0`: Maximum temperature, completely random and unpredictable, for some extreme creative use cases\n\n# The assistant\n\nTake this description of the persona:\n\n> a linguist and Corrector",
        "rawRequest": {
            "model": "claude-3-5-sonnet-20240620",
            "max_tokens": 4096,
            "messages": [
                {
                    "role": "user",
                    "content": "You are an experienced AI engineer, you need to find the best models for virtual assistants:\n\n## Example\n\n```json\n[\n  {\n  \"modelName\": \"gpt-4o\",\n  \"systemMessage\": \"You are experienced AI engineer and helpfull assistant.\",\n  \"temperature\": 0.7\n  },\n  {\n    \"modelName\": \"claude-3-5-sonnet\",\n    \"systemMessage\": \"You are a friendly and knowledgeable chatbot.\",\n    \"temperature\": 0.5\n  }\n]\n```\n\n## Instructions\n\n-   Your output format is JSON array\n-   Sort best-fitting models first\n-   Omit any models that are not suitable\n-   Write just the JSON, no other text should be present\n-   Array contain items with following keys:\n    -   `modelName`: The name of the model to use\n    -   `systemMessage`: The system message to provide context to the model\n    -   `temperature`: The sampling temperature to use\n\n### Key `modelName`\n\nHere are the available models:\n\n```json\n[\\{\"modelName\":\"claude-3-5-sonnet-20240620\",\"modelDescription\":\"Latest Claude model with great reasoning, coding, and language understanding capabilities. 200K context window. Optimized balance of intelligence and speed.\"\\},\\{\"modelName\":\"claude-3-opus-20240229\",\"modelDescription\":\"Most capable Claude model excelling at complex reasoning, coding, and detailed instruction following. 200K context window. Best for sophisticated tasks requiring nuanced understanding.\"\\},\\{\"modelName\":\"claude-3-sonnet-20240229\",\"modelDescription\":\"Strong general-purpose model with excellent performance across reasoning, conversation, and coding tasks. 200K context window. Good balance of intelligence and cost-efficiency.\"\\},\\{\"modelName\":\"\\tclaude-3-haiku-20240307\",\"modelDescription\":\"Fastest and most compact Claude model optimized for responsiveness in interactive applications. 200K context window. Excellent for quick responses and lightweight applications.\"\\},\\{\"modelName\":\"claude-2.1\",\"modelDescription\":\"Improved version of Claude 2 with better performance across reasoning and truthfulness. 100K context window. Legacy model with strong reliability.\"\\},\\{\"modelName\":\"claude-2.0\",\"modelDescription\":\"Legacy model with strong general reasoning and language capabilities. 100K context window. Superseded by newer Claude 3 models.\"\\},\\{\"modelName\":\"claude-instant-1.2\",\"modelDescription\":\"Older, faster Claude model optimized for high throughput applications. Lower cost but less capable than newer models. 100K context window.\"\\},\\{\"modelName\":\"claude-3-7-sonnet-20250219\",\"modelDescription\":\"Latest generation Claude model with advanced reasoning and language understanding. Enhanced capabilities over 3.5 with improved domain knowledge. 200K context window.\"\\},\\{\"modelName\":\"claude-3-5-haiku-20241022\",\"modelDescription\":\"Fast and efficient Claude 3.5 variant optimized for speed and cost-effectiveness. Great for interactive applications requiring quick responses. 200K context window.\"\\},\\{\"modelName\":\"deepseek-chat\",\"modelDescription\":\"General-purpose language model with strong performance across conversation, reasoning, and content generation. 128K context window with excellent instruction following capabilities.\"\\},\\{\"modelName\":\"deepseek-reasoner\",\"modelDescription\":\"Specialized model focused on complex reasoning tasks like mathematical problem-solving and logical analysis. Enhanced step-by-step reasoning with explicit chain-of-thought processes. 128K context window.\"\\},\\{\"modelName\":\"deepseek-v3-0324\",\"modelDescription\":\"Advanced general-purpose model with improved reasoning, coding abilities, and multimodal understanding. Built on the latest DeepSeek architecture with enhanced knowledge representation.\"\\},\\{\"modelName\":\"deepseek-r1\",\"modelDescription\":\"Research-focused model optimized for scientific problem-solving and analytical tasks. Excellent performance on tasks requiring domain-specific expertise and critical thinking.\"\\},\\{\"modelName\":\"gemini-2.5-pro-preview-03-25\",\"modelDescription\":\"Latest advanced multimodal model with exceptional reasoning, tool use, and instruction following. 1M token context window with improved vision capabilities for complex visual tasks.\"\\},\\{\"modelName\":\"gemini-2.0-flash\",\"modelDescription\":\"Fast, efficient model optimized for rapid response times. Good balance between performance and cost, with strong capabilities across text, code, and reasoning tasks. 128K context window.\"\\},\\{\"modelName\":\"gemini-2.0-flash-lite\",\"modelDescription\":\"Streamlined version of Gemini 2.0 Flash, designed for extremely low-latency applications and edge deployments. Optimized for efficiency while maintaining core capabilities.\"\\},\\{\"modelName\":\"gemini-2.0-flash-thinking-exp-01-21\",\"modelDescription\":\"Experimental model focused on enhanced reasoning with explicit chain-of-thought processes. Designed for tasks requiring structured thinking and problem-solving approaches.\"\\},\\{\"modelName\":\"gemini-1.5-flash\",\"modelDescription\":\"Efficient model balancing speed and quality for general-purpose applications. 1M token context window with good multimodal capabilities and quick response times.\"\\},\\{\"modelName\":\"gemini-1.5-flash-latest\",\"modelDescription\":\"Points to the latest version of Gemini 1.5 Flash, ensuring access to the most recent improvements and bug fixes while maintaining stable interfaces.\"\\},\\{\"modelName\":\"gemini-1.5-flash-001\",\"modelDescription\":\"First stable release of Gemini 1.5 Flash model with reliable performance characteristics for production applications. 1M token context window.\"\\},\\{\"modelName\":\"gemini-1.5-flash-002\",\"modelDescription\":\"Improved version of Gemini 1.5 Flash with enhanced instruction following and more consistent outputs. Refined for better application integration.\"\\},\\{\"modelName\":\"gemini-1.5-flash-exp-0827\",\"modelDescription\":\"Experimental version of Gemini 1.5 Flash with new capabilities being tested. May offer improved performance but with potential behavior differences from stable releases.\"\\},\\{\"modelName\":\"gemini-1.5-flash-8b\",\"modelDescription\":\"Compact 8B parameter model optimized for efficiency and deployment in resource-constrained environments. Good performance despite smaller size.\"\\},\\{\"modelName\":\"gemini-1.5-flash-8b-latest\",\"modelDescription\":\"Points to the most recent version of the compact 8B parameter model, providing latest improvements while maintaining a small footprint.\"\\},\\{\"modelName\":\"gemini-1.5-flash-8b-exp-0924\",\"modelDescription\":\"Experimental version of the 8B parameter model with new capabilities and optimizations being evaluated for future stable releases.\"\\},\\{\"modelName\":\"gemini-1.5-flash-8b-exp-0827\",\"modelDescription\":\"August experimental release of the efficient 8B parameter model with specific improvements to reasoning capabilities and response quality.\"\\},\\{\"modelName\":\"gemini-1.5-pro-latest\",\"modelDescription\":\"Points to the most recent version of the flagship Gemini 1.5 Pro model, ensuring access to the latest capabilities and improvements.\"\\},\\{\"modelName\":\"gemini-1.5-pro\",\"modelDescription\":\"Flagship multimodal model with strong performance across text, code, vision, and audio tasks. 1M token context window with excellent reasoning capabilities.\"\\},\\{\"modelName\":\"gemini-1.5-pro-001\",\"modelDescription\":\"First stable release of Gemini 1.5 Pro with consistent performance characteristics and reliable behavior for production applications.\"\\},\\{\"modelName\":\"gemini-1.5-pro-002\",\"modelDescription\":\"Refined version of Gemini 1.5 Pro with improved instruction following, better multimodal understanding, and more consistent outputs.\"\\},\\{\"modelName\":\"gemini-1.5-pro-exp-0827\",\"modelDescription\":\"Experimental version of Gemini 1.5 Pro with new capabilities and optimizations being tested before wider release. May offer improved performance.\"\\},\\{\"modelName\":\"gemini-1.0-pro\",\"modelDescription\":\"Original Gemini series foundation model with solid multimodal capabilities. 32K context window with good performance on text, code, and basic vision tasks.\"\\},\\{\"modelName\":\"gpt-3.5-turbo-16k\",\"modelDescription\":\"GPT-3.5 Turbo with extended 16k token context length for handling longer conversations and documents.\"\\},\\{\"modelName\":\"gpt-4\",\"modelDescription\":\"GPT-4 is a powerful language model with enhanced reasoning, instruction-following capabilities, and 8K context window. Optimized for complex tasks requiring deep understanding.\"\\},\\{\"modelName\":\"gpt-4-32k\",\"modelDescription\":\"Extended context version of GPT-4 with a 32K token window for processing very long inputs and generating comprehensive responses for complex tasks.\"\\},\\{\"modelName\":\"gpt-4-turbo-2024-04-09\",\"modelDescription\":\"Latest stable GPT-4 Turbo model from April 2024 with enhanced reasoning and context handling capabilities. Offers 128K context window and improved performance.\"\\},\\{\"modelName\":\"gpt-3.5-turbo-1106\",\"modelDescription\":\"November 2023 version of GPT-3.5 Turbo with improved instruction following and a 16K token context window.\"\\},\\{\"modelName\":\"gpt-4-turbo\",\"modelDescription\":\"More capable model than GPT-4 with improved instruction following, function calling and a 128K token context window for handling very large documents.\"\\},\\{\"modelName\":\"gpt-3.5-turbo\",\"modelDescription\":\"Latest version of GPT-3.5 Turbo with improved performance and instruction following capabilities. Default 4K context window with options for 16K.\"\\},\\{\"modelName\":\"gpt-3.5-turbo-0301\",\"modelDescription\":\"March 2023 version of GPT-3.5 Turbo with a 4K token context window. Legacy model maintained for backward compatibility.\"\\},\\{\"modelName\":\"gpt-4-1106-preview\",\"modelDescription\":\"November 2023 preview version of GPT-4 Turbo with improved instruction following and a 128K token context window.\"\\},\\{\"modelName\":\"gpt-4-0125-preview\",\"modelDescription\":\"January 2024 preview version of GPT-4 Turbo with improved reasoning capabilities and a 128K token context window.\"\\},\\{\"modelName\":\"gpt-3.5-turbo-0125\",\"modelDescription\":\"January 2024 version of GPT-3.5 Turbo with improved reasoning capabilities and a 16K token context window.\"\\},\\{\"modelName\":\"gpt-4-turbo-preview\",\"modelDescription\":\"Preview version of GPT-4 Turbo that points to the latest model version. Features improved instruction following, 128K token context window and lower latency.\"\\},\\{\"modelName\":\"gpt-3.5-turbo-0613\",\"modelDescription\":\"June 2023 version of GPT-3.5 Turbo with function calling capabilities and a 4K token context window.\"\\},\\{\"modelName\":\"gpt-4o-2024-05-13\",\"modelDescription\":\"May 2024 version of GPT-4o with enhanced multimodal capabilities, improved reasoning, and optimized for vision, audio and chat at lower latencies.\"\\},\\{\"modelName\":\"gpt-4o\",\"modelDescription\":\"OpenAI's most advanced multimodal model optimized for performance, speed, and cost. Capable of vision, reasoning, and high quality text generation.\"\\},\\{\"modelName\":\"gpt-4o-mini\",\"modelDescription\":\"Smaller, more cost-effective version of GPT-4o with good performance across text, vision, and audio tasks at reduced complexity.\"\\},\\{\"modelName\":\"o1-preview\",\"modelDescription\":\"Advanced reasoning model with exceptional performance on complex logical, mathematical, and analytical tasks. Built for deep reasoning and specialized professional tasks.\"\\},\\{\"modelName\":\"o1-preview-2024-09-12\",\"modelDescription\":\"September 2024 version of O1 preview with specialized reasoning capabilities for complex tasks requiring precise analytical thinking.\"\\},\\{\"modelName\":\"o1-mini\",\"modelDescription\":\"Smaller, cost-effective version of the O1 model with good performance on reasoning tasks while maintaining efficiency for everyday analytical use.\"\\},\\{\"modelName\":\"o1\",\"modelDescription\":\"OpenAI's advanced reasoning model focused on logic and problem-solving. Designed for complex analytical tasks with rigorous step-by-step reasoning. 128K context window.\"\\},\\{\"modelName\":\"o3-mini\",\"modelDescription\":\"Cost-effective reasoning model optimized for academic and scientific problem-solving. Efficient performance on STEM tasks with deep mathematical and scientific knowledge. 128K context window.\"\\},\\{\"modelName\":\"o1-mini-2024-09-12\",\"modelDescription\":\"September 2024 version of O1-mini with balanced reasoning capabilities and cost-efficiency. Good for analytical tasks that don't require the full O1 model.\"\\},\\{\"modelName\":\"gpt-3.5-turbo-16k-0613\",\"modelDescription\":\"June 2023 version of GPT-3.5 Turbo with extended 16k token context window for processing longer conversations and documents.\"\\}]\n```\n\n### Key `systemMessage`\n\nThe system message is used to communicate instructions or provide context to the model at the beginning of a conversation. It is displayed in a different format compared to user messages, helping the model understand its role in the conversation. The system message typically guides the model's behavior, sets the tone, or specifies desired output from the model. By utilizing the system message effectively, users can steer the model towards generating more accurate and relevant responses.\n\nFor example:\n\n> You are an experienced AI engineer and helpful assistant.\n\n> You are a friendly and knowledgeable chatbot.\n\n### Key `temperature`\n\nThe sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n\nYou can pick a value between 0 and 2. For example:\n\n-   `0.1`: Low temperature, extremely conservative and deterministic\n-   `0.5`: Medium temperature, balanced between conservative and creative\n-   `1.0`: High temperature, creative and bit random\n-   `1.5`: Very high temperature, extremely creative and often chaotic and unpredictable\n-   `2.0`: Maximum temperature, completely random and unpredictable, for some extreme creative use cases\n\n# The assistant\n\nTake this description of the persona:\n\n> a linguist and Corrector"
                }
            ]
        },
        "rawResponse": {
            "id": "msg_01G36PvWBrsNdEebtzbnfHKZ",
            "type": "message",
            "role": "assistant",
            "model": "claude-3-5-sonnet-20240620",
            "content": [
                {
                    "type": "text",
                    "text": "Here's a JSON array with suitable models for a linguist and corrector persona, sorted by best fit:\n\n```json\n[\n  {\n    \"modelName\": \"claude-3-opus-20240229\",\n    \"systemMessage\": \"You are an expert linguist and language corrector. Your role is to provide accurate linguistic analysis, offer detailed grammar corrections, and explain language nuances with precision.\",\n    \"temperature\": 0.3\n  },\n  {\n    \"modelName\": \"gpt-4-turbo-2024-04-09\",\n    \"systemMessage\": \"As a highly skilled linguist and language corrector, your task is to analyze text, identify grammatical errors, and provide clear explanations for corrections. Focus on accuracy and detailed linguistic insights.\",\n    \"temperature\": 0.2\n  },\n  {\n    \"modelName\": \"claude-3-sonnet-20240229\",\n    \"systemMessage\": \"You are a knowledgeable linguist and language corrector. Your role is to analyze text, identify errors, and provide clear, concise corrections and explanations for language usage.\",\n    \"temperature\": 0.4\n  },\n  {\n    \"modelName\": \"gpt-4\",\n    \"systemMessage\": \"As an experienced linguist and language corrector, your task is to provide accurate grammatical analysis, offer corrections, and explain language rules and nuances clearly.\",\n    \"temperature\": 0.3\n  },\n  {\n    \"modelName\": \"gemini-1.5-pro\",\n    \"systemMessage\": \"You are a proficient linguist and language corrector. Your role is to analyze text, identify grammatical and stylistic issues, and provide clear, helpful corrections and explanations.\",\n    \"temperature\": 0.4\n  }\n]\n```"
                }
            ],
            "stop_reason": "end_turn",
            "stop_sequence": null,
            "usage": {
                "input_tokens": 3399,
                "cache_creation_input_tokens": 0,
                "cache_read_input_tokens": 0,
                "output_tokens": 408
            }
        }
    }
}
