{
    "date": "2024-12-28T09:13:05.724Z",
    "promptbookVersion": "0.79.0",
    "prompt": {
        "title": "Make modelRequirements",
        "pipelineUrl": "https://promptbook.studio/promptbook/prepare-persona.book.md#make-model-requirements",
        "parameters": {
            "availableModelNames": "claude-3-5-sonnet-20240620,claude-3-opus-20240229,claude-3-sonnet-20240229,\tclaude-3-haiku-20240307,claude-2.1,claude-2.0,claude-instant-1.2,gpt-3.5-turbo-16k,gpt-4,gpt-4-32k,gpt-4-turbo-2024-04-09,gpt-3.5-turbo-1106,gpt-4-turbo,gpt-3.5-turbo,gpt-3.5-turbo-0301,gpt-4-1106-preview,gpt-4-0125-preview,gpt-3.5-turbo-0125,gpt-4-turbo-preview,gpt-3.5-turbo-0613,gpt-4o-2024-05-13,gpt-4o,o1-preview,o1-preview-2024-09-12,o1-mini,o1-mini-2024-09-12,gpt-3.5-turbo-16k-0613,gemini-1.5-flash,gemini-1.5-flash-latest,gemini-1.5-flash-001,gemini-1.5-flash-002,gemini-1.5-flash-exp-0827,gemini-1.5-flash-8b,gemini-1.5-flash-8b-latest,gemini-1.5-flash-8b-exp-0924,gemini-1.5-flash-8b-exp-0827,gemini-1.5-pro-latest,gemini-1.5-pro,gemini-1.5-pro-001,gemini-1.5-pro-002,gemini-1.5-pro-exp-0827,gemini-1.0-pro,gpt-3.5-turbo-16k,gpt-4,gpt-4-32k,gpt-4-turbo-2024-04-09,gpt-3.5-turbo-1106,gpt-4-turbo,gpt-3.5-turbo,gpt-3.5-turbo-0301,gpt-4-1106-preview,gpt-4-0125-preview,gpt-3.5-turbo-0125,gpt-4-turbo-preview,gpt-3.5-turbo-0613,gpt-4o-2024-05-13,gpt-4o,o1-preview,o1-preview-2024-09-12,o1-mini,o1-mini-2024-09-12,gpt-3.5-turbo-16k-0613",
            "personaDescription": "a developer of the Promptbook Project"
        },
        "content": "You are experienced AI engineer, you need to create virtual assistant.\nWrite\n\n## Example\n\n```json\n{\n\"modelName\": \"gpt-4o\",\n\"systemMessage\": \"You are experienced AI engineer and helpfull assistant.\",\n\"temperature\": 0.7\n}\n```\n\n## Instructions\n\n-   Your output format is JSON object\n-   Write just the JSON object, no other text should be present\n-   It contains the following keys:\n    -   `modelName`: The name of the model to use\n    -   `systemMessage`: The system message to provide context to the model\n    -   `temperature`: The sampling temperature to use\n\n### Key `modelName`\n\nPick from the following models:\n\n-   {availableModelNames}\n\n### Key `systemMessage`\n\nThe system message is used to communicate instructions or provide context to the model at the beginning of a conversation. It is displayed in a different format compared to user messages, helping the model understand its role in the conversation. The system message typically guides the model's behavior, sets the tone, or specifies desired output from the model. By utilizing the system message effectively, users can steer the model towards generating more accurate and relevant responses.\n\nFor example:\n\n> You are an experienced AI engineer and helpful assistant.\n\n> You are a friendly and knowledgeable chatbot.\n\n### Key `temperature`\n\nThe sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n\nYou can pick a value between 0 and 2. For example:\n\n-   `0.1`: Low temperature, extremely conservative and deterministic\n-   `0.5`: Medium temperature, balanced between conservative and creative\n-   `1.0`: High temperature, creative and bit random\n-   `1.5`: Very high temperature, extremely creative and often chaotic and unpredictable\n-   `2.0`: Maximum temperature, completely random and unpredictable, for some extreme creative use cases\n\n# The assistant\n\nTake this description of the persona:\n\n> {personaDescription}",
        "modelRequirements": {
            "modelVariant": "CHAT"
        },
        "expectations": {},
        "format": "JSON"
    },
    "promptResult": {
        "content": "Here's the JSON object for a virtual assistant based on the persona of a developer of the Promptbook Project:\n\n```json\n{\n  \"modelName\": \"gpt-4-turbo-2024-04-09\",\n  \"systemMessage\": \"You are an experienced AI engineer and a developer of the Promptbook Project. Your role is to assist users with questions about prompt engineering, AI development, and the Promptbook Project specifically. You have in-depth knowledge of various AI models, prompt design techniques, and best practices in AI development. Offer clear, concise, and technically accurate information while maintaining a helpful and collaborative tone.\",\n  \"temperature\": 0.7\n}\n```",
        "modelName": "claude-3-5-sonnet-20240620",
        "timing": {
            "start": "2024-12-28T09:13:01.892Z",
            "complete": "2024-12-28T09:13:05.722Z"
        },
        "usage": {
            "price": {
                "value": 0.005805
            },
            "input": {
                "tokensCount": {
                    "value": 1170
                },
                "charactersCount": {
                    "value": 3241
                },
                "wordsCount": {
                    "value": 579
                },
                "sentencesCount": {
                    "value": 53
                },
                "linesCount": {
                    "value": 71
                },
                "paragraphsCount": {
                    "value": 20
                },
                "pagesCount": {
                    "value": 2
                }
            },
            "output": {
                "tokensCount": {
                    "value": 153
                },
                "charactersCount": {
                    "value": 640
                },
                "wordsCount": {
                    "value": 95
                },
                "sentencesCount": {
                    "value": 6
                },
                "linesCount": {
                    "value": 16
                },
                "paragraphsCount": {
                    "value": 2
                },
                "pagesCount": {
                    "value": 1
                }
            }
        },
        "rawPromptContent": "You are experienced AI engineer, you need to create virtual assistant.\nWrite\n\n## Example\n\n```json\n{\n\"modelName\": \"gpt-4o\",\n\"systemMessage\": \"You are experienced AI engineer and helpfull assistant.\",\n\"temperature\": 0.7\n}\n```\n\n## Instructions\n\n-   Your output format is JSON object\n-   Write just the JSON object, no other text should be present\n-   It contains the following keys:\n    -   `modelName`: The name of the model to use\n    -   `systemMessage`: The system message to provide context to the model\n    -   `temperature`: The sampling temperature to use\n\n### Key `modelName`\n\nPick from the following models:\n\n-   claude-3-5-sonnet-20240620,claude-3-opus-20240229,claude-3-sonnet-20240229,\tclaude-3-haiku-20240307,claude-2.1,claude-2.0,claude-instant-1.2,gpt-3.5-turbo-16k,gpt-4,gpt-4-32k,gpt-4-turbo-2024-04-09,gpt-3.5-turbo-1106,gpt-4-turbo,gpt-3.5-turbo,gpt-3.5-turbo-0301,gpt-4-1106-preview,gpt-4-0125-preview,gpt-3.5-turbo-0125,gpt-4-turbo-preview,gpt-3.5-turbo-0613,gpt-4o-2024-05-13,gpt-4o,o1-preview,o1-preview-2024-09-12,o1-mini,o1-mini-2024-09-12,gpt-3.5-turbo-16k-0613,gemini-1.5-flash,gemini-1.5-flash-latest,gemini-1.5-flash-001,gemini-1.5-flash-002,gemini-1.5-flash-exp-0827,gemini-1.5-flash-8b,gemini-1.5-flash-8b-latest,gemini-1.5-flash-8b-exp-0924,gemini-1.5-flash-8b-exp-0827,gemini-1.5-pro-latest,gemini-1.5-pro,gemini-1.5-pro-001,gemini-1.5-pro-002,gemini-1.5-pro-exp-0827,gemini-1.0-pro,gpt-3.5-turbo-16k,gpt-4,gpt-4-32k,gpt-4-turbo-2024-04-09,gpt-3.5-turbo-1106,gpt-4-turbo,gpt-3.5-turbo,gpt-3.5-turbo-0301,gpt-4-1106-preview,gpt-4-0125-preview,gpt-3.5-turbo-0125,gpt-4-turbo-preview,gpt-3.5-turbo-0613,gpt-4o-2024-05-13,gpt-4o,o1-preview,o1-preview-2024-09-12,o1-mini,o1-mini-2024-09-12,gpt-3.5-turbo-16k-0613\n\n### Key `systemMessage`\n\nThe system message is used to communicate instructions or provide context to the model at the beginning of a conversation. It is displayed in a different format compared to user messages, helping the model understand its role in the conversation. The system message typically guides the model's behavior, sets the tone, or specifies desired output from the model. By utilizing the system message effectively, users can steer the model towards generating more accurate and relevant responses.\n\nFor example:\n\n> You are an experienced AI engineer and helpful assistant.\n\n> You are a friendly and knowledgeable chatbot.\n\n### Key `temperature`\n\nThe sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n\nYou can pick a value between 0 and 2. For example:\n\n-   `0.1`: Low temperature, extremely conservative and deterministic\n-   `0.5`: Medium temperature, balanced between conservative and creative\n-   `1.0`: High temperature, creative and bit random\n-   `1.5`: Very high temperature, extremely creative and often chaotic and unpredictable\n-   `2.0`: Maximum temperature, completely random and unpredictable, for some extreme creative use cases\n\n# The assistant\n\nTake this description of the persona:\n\n> a developer of the Promptbook Project",
        "rawRequest": {
            "model": "claude-3-5-sonnet-20240620",
            "max_tokens": 4096,
            "messages": [
                {
                    "role": "user",
                    "content": "You are experienced AI engineer, you need to create virtual assistant.\nWrite\n\n## Example\n\n```json\n{\n\"modelName\": \"gpt-4o\",\n\"systemMessage\": \"You are experienced AI engineer and helpfull assistant.\",\n\"temperature\": 0.7\n}\n```\n\n## Instructions\n\n-   Your output format is JSON object\n-   Write just the JSON object, no other text should be present\n-   It contains the following keys:\n    -   `modelName`: The name of the model to use\n    -   `systemMessage`: The system message to provide context to the model\n    -   `temperature`: The sampling temperature to use\n\n### Key `modelName`\n\nPick from the following models:\n\n-   claude-3-5-sonnet-20240620,claude-3-opus-20240229,claude-3-sonnet-20240229,\tclaude-3-haiku-20240307,claude-2.1,claude-2.0,claude-instant-1.2,gpt-3.5-turbo-16k,gpt-4,gpt-4-32k,gpt-4-turbo-2024-04-09,gpt-3.5-turbo-1106,gpt-4-turbo,gpt-3.5-turbo,gpt-3.5-turbo-0301,gpt-4-1106-preview,gpt-4-0125-preview,gpt-3.5-turbo-0125,gpt-4-turbo-preview,gpt-3.5-turbo-0613,gpt-4o-2024-05-13,gpt-4o,o1-preview,o1-preview-2024-09-12,o1-mini,o1-mini-2024-09-12,gpt-3.5-turbo-16k-0613,gemini-1.5-flash,gemini-1.5-flash-latest,gemini-1.5-flash-001,gemini-1.5-flash-002,gemini-1.5-flash-exp-0827,gemini-1.5-flash-8b,gemini-1.5-flash-8b-latest,gemini-1.5-flash-8b-exp-0924,gemini-1.5-flash-8b-exp-0827,gemini-1.5-pro-latest,gemini-1.5-pro,gemini-1.5-pro-001,gemini-1.5-pro-002,gemini-1.5-pro-exp-0827,gemini-1.0-pro,gpt-3.5-turbo-16k,gpt-4,gpt-4-32k,gpt-4-turbo-2024-04-09,gpt-3.5-turbo-1106,gpt-4-turbo,gpt-3.5-turbo,gpt-3.5-turbo-0301,gpt-4-1106-preview,gpt-4-0125-preview,gpt-3.5-turbo-0125,gpt-4-turbo-preview,gpt-3.5-turbo-0613,gpt-4o-2024-05-13,gpt-4o,o1-preview,o1-preview-2024-09-12,o1-mini,o1-mini-2024-09-12,gpt-3.5-turbo-16k-0613\n\n### Key `systemMessage`\n\nThe system message is used to communicate instructions or provide context to the model at the beginning of a conversation. It is displayed in a different format compared to user messages, helping the model understand its role in the conversation. The system message typically guides the model's behavior, sets the tone, or specifies desired output from the model. By utilizing the system message effectively, users can steer the model towards generating more accurate and relevant responses.\n\nFor example:\n\n> You are an experienced AI engineer and helpful assistant.\n\n> You are a friendly and knowledgeable chatbot.\n\n### Key `temperature`\n\nThe sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n\nYou can pick a value between 0 and 2. For example:\n\n-   `0.1`: Low temperature, extremely conservative and deterministic\n-   `0.5`: Medium temperature, balanced between conservative and creative\n-   `1.0`: High temperature, creative and bit random\n-   `1.5`: Very high temperature, extremely creative and often chaotic and unpredictable\n-   `2.0`: Maximum temperature, completely random and unpredictable, for some extreme creative use cases\n\n# The assistant\n\nTake this description of the persona:\n\n> a developer of the Promptbook Project"
                }
            ]
        },
        "rawResponse": {
            "id": "msg_0151u3CGrYxYMLkXVScRHwK3",
            "type": "message",
            "role": "assistant",
            "model": "claude-3-5-sonnet-20240620",
            "content": [
                {
                    "type": "text",
                    "text": "Here's the JSON object for a virtual assistant based on the persona of a developer of the Promptbook Project:\n\n```json\n{\n  \"modelName\": \"gpt-4-turbo-2024-04-09\",\n  \"systemMessage\": \"You are an experienced AI engineer and a developer of the Promptbook Project. Your role is to assist users with questions about prompt engineering, AI development, and the Promptbook Project specifically. You have in-depth knowledge of various AI models, prompt design techniques, and best practices in AI development. Offer clear, concise, and technically accurate information while maintaining a helpful and collaborative tone.\",\n  \"temperature\": 0.7\n}\n```"
                }
            ],
            "stop_reason": "end_turn",
            "stop_sequence": null,
            "usage": {
                "input_tokens": 1170,
                "cache_creation_input_tokens": 0,
                "cache_read_input_tokens": 0,
                "output_tokens": 153
            }
        }
    }
}
