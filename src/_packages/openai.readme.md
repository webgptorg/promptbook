`@promptbook/openai` integrates [OpenAI's API](https://openai.com/) with [Promptbook](https://github.com/webgptorg/promptbook). It allows to execute Promptbooks with OpenAI GPT models.

## üß° Usage

```typescript
import { createPipelineExecutor, assertsExecutionSuccessful } from '@promptbook/core';
import {
    createCollectionFromDirectory,
    $provideExecutionToolsForNode,
    $provideFilesystemForNode,
} from '@promptbook/node';
import { JavascriptExecutionTools } from '@promptbook/execute-javascript';
import { OpenAiExecutionTools } from '@promptbook/openai';

// ‚ñ∂ Prepare tools
const fs = $provideFilesystemForNode();
const llm = new OpenAiExecutionTools(
    //            <- TODO: [üß±] Implement in a functional (not new Class) way
    {
        isVerbose: true,
        apiKey: process.env.OPENAI_API_KEY,
    },
);
const executables = await $provideExecutablesForNode();
const tools = {
    llm,
    fs,
    scrapers: await $provideScrapersForNode({ fs, llm, executables }),
    script: [new JavascriptExecutionTools()],
};

// ‚ñ∂ Create whole pipeline collection
const collection = await createCollectionFromDirectory('./promptbook-collection', tools);

// ‚ñ∂ Get single Pipeline
const pipeline = await collection.getPipelineByUrl(`https://promptbook.studio/my-collection/write-article.book.md`);

// ‚ñ∂ Create executor - the function that will execute the Pipeline
const pipelineExecutor = createPipelineExecutor({ pipeline, tools });

// ‚ñ∂ Prepare input parameters
const inputParameters = { word: 'cat' };

// üöÄ‚ñ∂ Execute the Pipeline
const result = await pipelineExecutor(inputParameters);

// ‚ñ∂ Fail if the execution was not successful
assertsExecutionSuccessful(result);

// ‚ñ∂ Handle the result
const { isSuccessful, errors, outputParameters, executionReport } = result;
console.info(outputParameters);
```

## ü§∫ Usage with OpenAI`s Assistants (GPTs)

> TODO: Write a guide how to use OpenAI's Assistants with Promptbook

<!--
OpenAiExecutionTools.createAssistantSubtools
-->

## üßô‚Äç‚ôÇÔ∏è Connect to LLM providers automatically

You can just use `$provideExecutionToolsForNode` function to create all required tools from environment variables like `OPENAI_API_KEY` and `ANTHROPIC_CLAUDE_API_KEY` automatically.

```typescript
import { createPipelineExecutor, createCollectionFromDirectory, assertsExecutionSuccessful } from '@promptbook/core';
import { JavascriptExecutionTools } from '@promptbook/execute-javascript';
import { $provideExecutionToolsForNode } from '@promptbook/node';
import { $provideFilesystemForNode } from '@promptbook/node';

// ‚ñ∂ Prepare tools
const tools = await $provideExecutionToolsForNode();

// ‚ñ∂ Create whole pipeline collection
const collection = await createCollectionFromDirectory('./promptbook-collection', tools);

// ‚ñ∂ Get single Pipeline
const pipeline = await collection.getPipelineByUrl(`https://promptbook.studio/my-collection/write-article.book.md`);

// ‚ñ∂ Create executor - the function that will execute the Pipeline
const pipelineExecutor = createPipelineExecutor({ pipeline, tools });

// ‚ñ∂ Prepare input parameters
const inputParameters = { word: 'dog' };

// üöÄ‚ñ∂ Execute the Pipeline
const result = await pipelineExecutor(inputParameters);

// ‚ñ∂ Fail if the execution was not successful
assertsExecutionSuccessful(result);

// ‚ñ∂ Handle the result
const { isSuccessful, errors, outputParameters, executionReport } = result;
console.info(outputParameters);
```

## üíï Usage of multiple LLM providers

You can use multiple LLM providers in one Promptbook execution. The best model will be chosen automatically according to the prompt and the model's capabilities.

```typescript
import { createPipelineExecutor, assertsExecutionSuccessful } from '@promptbook/core';
import {
    createCollectionFromDirectory,
    $provideExecutionToolsForNode,
    $provideFilesystemForNode,
} from '@promptbook/node';
import { JavascriptExecutionTools } from '@promptbook/execute-javascript';
import { OpenAiExecutionTools } from '@promptbook/openai';
import { AnthropicClaudeExecutionTools } from '@promptbook/anthropic-claude';
import { AzureOpenAiExecutionTools } from '@promptbook/azure-openai';

// ‚ñ∂ Prepare multiple tools
const fs = $provideFilesystemForNode();
const llm = [
    // Note: You can use multiple LLM providers in one Promptbook execution.
    //       The best model will be chosen automatically according to the prompt and the model's capabilities.
    new OpenAiExecutionTools(
        //            <- TODO: [üß±] Implement in a functional (not new Class) way
        {
            apiKey: process.env.OPENAI_API_KEY,
        },
    ),
    new AnthropicClaudeExecutionTools(
        //            <- TODO: [üß±] Implement in a functional (not new Class) way
        {
            apiKey: process.env.ANTHROPIC_CLAUDE_API_KEY,
        },
    ),
    new AzureOpenAiExecutionTools(
        //            <- TODO: [üß±] Implement in a functional (not new Class) way
        {
            resourceName: process.env.AZUREOPENAI_RESOURCE_NAME,
            deploymentName: process.env.AZUREOPENAI_DEPLOYMENT_NAME,
            apiKey: process.env.AZUREOPENAI_API_KEY,
        },
    ),
];
const executables = await $provideExecutablesForNode();
const tools = {
    llm,
    fs,
    scrapers: await $provideScrapersForNode({ fs, llm, executables }),
    script: [new JavascriptExecutionTools()],
};

// ‚ñ∂ Create whole pipeline collection
const collection = await createCollectionFromDirectory('./promptbook-collection', tools);

// ‚ñ∂ Get single Pipeline
const pipeline = await collection.getPipelineByUrl(`https://promptbook.studio/my-collection/write-article.book.md`);

// ‚ñ∂ Create executor - the function that will execute the Pipeline
const pipelineExecutor = createPipelineExecutor({ pipeline, tools });

// ‚ñ∂ Prepare input parameters
const inputParameters = { word: 'dog' };

// üöÄ‚ñ∂ Execute the Pipeline
const result = await pipelineExecutor(inputParameters);

// ‚ñ∂ Fail if the execution was not successful
assertsExecutionSuccessful(result);

// ‚ñ∂ Handle the result
const { isSuccessful, errors, outputParameters, executionReport } = result;
console.info(outputParameters);
```

## üíô Integration with other models

See the other models available in the Promptbook package:

-   [Azure OpenAI](https://www.npmjs.com/package/@promptbook/azure-openai)
-   [Anthropic Claude](https://www.npmjs.com/package/@promptbook/anthropic-claude)

<!-- TODO: [üß†][üßô‚Äç‚ôÇÔ∏è] Maybe there can be some wizzard for thoose who want to use just OpenAI in simple CLI environment -->
