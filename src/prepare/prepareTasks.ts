import { spaceTrim } from 'spacetrim';
import { DEFAULT_MAX_PARALLEL_COUNT } from '../config';
import type { ExecutionTools } from '../execution/ExecutionTools';
import { forEachAsync } from '../execution/utils/forEachAsync';
import type { PipelineJson } from '../pipeline/PipelineJson/PipelineJson';
import type { TaskJson } from '../pipeline/PipelineJson/TaskJson';
import { TODO_USE } from '../utils/organization/TODO_USE';
import type { PrepareAndScrapeOptions } from './PrepareAndScrapeOptions';

type PrepareTaskInput = Pick<PipelineJson, 'tasks' | 'parameters'> & {
    /**
     * @@@
     */
    readonly knowledgePiecesCount: number;
};

type PreparedTasks = {
    /**
     * @@@ Sequence of tasks that are chained together to form a pipeline
     */
    readonly tasksPrepared: ReadonlyArray<TaskJson>;
};

/**
 * @@@
 *
 * @public exported from `@promptbook/core`
 */
export async function prepareTasks(
    pipeline: PrepareTaskInput,
    tools: Pick<ExecutionTools, 'llm' | 'fs' | 'scrapers'>,
    options: PrepareAndScrapeOptions,
): Promise<PreparedTasks> {
    const { maxParallelCount = DEFAULT_MAX_PARALLEL_COUNT } = options;
    const { tasks, parameters, knowledgePiecesCount } = pipeline;

    // TODO: [main] Apply examples to each task (if missing and is for the task defined)
    TODO_USE(parameters);

    // TODO: [ðŸ–Œ][ðŸ§ ] Implement some `mapAsync` function
    const tasksPrepared: Array<TaskJson> = new Array(tasks.length);
    await forEachAsync(
        tasks,
        { maxParallelCount /* <- TODO: [ðŸª‚] When there are subtasks, this maximul limit can be broken */ },
        async (task, index) => {
            let { /* preparedContent <- TODO: Maybe use [ðŸ§Š] */ dependentParameterNames } = task;
            let preparedContent: string | undefined = undefined;

            if (knowledgePiecesCount > 0 && !dependentParameterNames.includes('knowledge')) {
                preparedContent = spaceTrim(`
                    {content}

                    ## Knowledge

                    {knowledge}
                `);
                // <- TODO: [ðŸ§ ][ðŸ§»] Cutomize shape/language/formatting of the addition to the prompt

                dependentParameterNames = [
                    ...dependentParameterNames,
                    'knowledge',
                    // <- [ðŸ·] There is the reverse process to remove {knowledge} from `dependentParameterNames`
                ];
            }

            const preparedTask: TaskJson = {
                ...task,
                dependentParameterNames,
                preparedContent,
                // <- TODO: [ðŸ™] Make some standard order of json properties
            };

            tasksPrepared[index] = preparedTask;
        },
    );

    return { tasksPrepared };
}

/**
 * TODO: [ðŸ˜‚] Adding knowledge should be convert to async high-level abstractions, simmilar thing with expectations to sync high-level abstractions
 * TODO: [ðŸ§ ] Add context to each task (if missing)
 * TODO: [ðŸ§ ] What is better name `prepareTask` or `prepareTaskAndParameters`
 * TODO: [â™¨][main] !!3 Prepare index the examples and maybe tasks
 * TODO: Write tests for `preparePipeline`
 * TODO: [ðŸ] Leverage the batch API and build queues @see https://platform.openai.com/docs/guides/batch
 * TODO: [ðŸ§Š] In future one preparation can take data from previous preparation and save tokens and time
 * TODO: [ðŸ› ] Actions, instruments (and maybe knowledge) => Functions and tools
 */
